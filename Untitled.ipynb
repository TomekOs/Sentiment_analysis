{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Introduction\n",
    "\n",
    "**Project name:** Sentiment analysis for IMDB reviews <br>\n",
    "Autor: Tomasz Ostaszewicz <br>\n",
    "Implementation: pandas, matplotlib, scikit-learn, keras.\n",
    "\n",
    "**Description:** This is sentiment analysis for IMDB reviews. The aim of the analysis is to predict if movie review form IMDB is positive or negative (binary classification problem). To predict sentiment different preprocessing schemes and machine learning and deep learning models were used, including:\n",
    "\n",
    "1. Classical machine learning models:\n",
    "    1. Data preprocessing: removing stop words, removing punctuation, expanding contractions, stemming, \n",
    "    2. Input data from: Count variables, TFidf variables\n",
    "    2. Models: Logistic Regression, SVM, Random Forest, Naive Bayes, XGBoost\n",
    "2. Deep learning models:\n",
    "    1. Data preprocessing: removing punctuation\n",
    "    2. Input data from: Embeddings (from Glove model)\n",
    "    3. Models: Simple RNN, LSTM, LSTM Bidirectional, LSTM Bidirectional with dropout, GRU, GRU Bidirectional, GRU Bidirectional with dropout\n",
    "\n",
    "Conclusions of analysis are presented at the end of each section.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import string\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.base import TransformerMixin, ClassifierMixin\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "import itertools\n",
    "import os\n",
    "import IPython\n",
    "\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "\n",
    "## Downloading input data\n",
    "\n",
    "Create directories for input and output data.\n",
    "\n",
    "def create_dir(d):\n",
    "    if not os.path.exists(d):\n",
    "        os.makedirs(d)\n",
    "    return None\n",
    "\n",
    "create_dir(\"01 Input data\")\n",
    "create_dir(\"02 Output data\")\n",
    "\n",
    "Download data manually from Kaggle into subfolder \"01 Input data\" created above.\n",
    "Use this link to download data: https://www.kaggle.com/c/word2vec-nlp-tutorial/data\n",
    "Two files are needed: labeledTrainData.tsv.zip, testData.tsv.zip\n",
    "Extract those files into \"01 Input data\" subdirectory.\n",
    "Names of extracted files are: labeledTrainData.tsv, testData.tsv\n",
    "\n",
    "Download manually file glove.6B.zip with GloVe vectors into subfolder \"01 Input data\" created above. \n",
    "Use this link to download data: http://nlp.stanford.edu/data/glove.6B.zip\n",
    "Extract file: glove.6B.300d.txt into \"01 Input data\" subdirectory.\n",
    "\n",
    "## Input data analysis\n",
    "\n",
    "Read data.\n",
    "\n",
    "kaggle_input_data_train = pd.read_csv('01 Input data/labeledTrainData.tsv', sep='\\t', index_col = 'id')\n",
    "kaggle_input_data_test = pd.read_csv('01 Input data/testData.tsv', sep='\\t', index_col = 'id')\n",
    "\n",
    "kaggle_input_data_train.info()\n",
    "\n",
    "# Checking data types for train\n",
    "print(kaggle_input_data_train.info())\n",
    "\n",
    "# Checking individuals rows\n",
    "print(kaggle_input_data_train.head(5))\n",
    "print(kaggle_input_data_train.sample(5))\n",
    "print(kaggle_input_data_train.tail(5))\n",
    "\n",
    "# Checking data types for test\n",
    "print(kaggle_input_data_test.info())\n",
    "\n",
    "# Checking individuals rows\n",
    "print(kaggle_input_data_test.head(5))\n",
    "print(kaggle_input_data_test.sample(5))\n",
    "print(kaggle_input_data_test.tail(5))\n",
    "\n",
    "**Conclusions for reading from train and test data:**\n",
    "1. reading from tsv files is correct\n",
    "2. No null values in review and sentiment columns\n",
    "\n",
    "Target variable distribution check.\n",
    "\n",
    "print(kaggle_input_data_train.sentiment.value_counts())\n",
    "print(kaggle_input_data_train.sentiment.value_counts(normalize=True))\n",
    "\n",
    "Conclusion:\n",
    "Target variable classes' share is 50%, 50%. No problem of imbalanced classes in data.\n",
    "\n",
    "## Sample split\n",
    "\n",
    "Assumptions about sample split:\n",
    "1. Number of observations in training sample: 25 000\n",
    "2. Split:\n",
    "   a. 20 000 observations for training sample,\n",
    "   b. 5 000 observatins for hold-out sample\n",
    "3. Training is done on 20 000 observations using 3-kfold cross-validation for classical models\n",
    "4. Test dataset from kaggle: kaggle_input_data_test does not containt target variable. It be used as additinal independent verification of a few best models\n",
    "\n",
    "# Sample split with stratified splitting is done\n",
    "X_train, X_test, y_train, y_test = train_test_split(kaggle_input_data_train.review, kaggle_input_data_train.sentiment, \n",
    "                                                    test_size=5000, random_state=123,\n",
    "                                                   stratify=kaggle_input_data_train.sentiment)\n",
    "\n",
    "print(y_train.shape, y_train.sum())\n",
    "print(y_test.shape, y_test.sum())\n",
    "\n",
    "## Data preprocessing\n",
    "\n",
    "Assumption:\n",
    "Data preprocessing is done on whole training sample as a separate step to speed-up cross-validation step\n",
    "Data preprocessing - especially stemming is time consuming.\n",
    "\n",
    "Create dict that will be used for expanding contractions.\n",
    "\n",
    "# This contraction dict was copied from:\n",
    "# https://gist.github.com/nealrs/96342d8231b75cf4bb82\n",
    "\n",
    "contractons_dict = {\n",
    "  \"ain't\": \"am not\",\n",
    "  \"aren't\": \"are not\",\n",
    "  \"can't\": \"cannot\",\n",
    "  \"can't've\": \"cannot have\",\n",
    "  \"'cause\": \"because\",\n",
    "  \"could've\": \"could have\",\n",
    "  \"couldn't\": \"could not\",\n",
    "  \"couldn't've\": \"could not have\",\n",
    "  \"didn't\": \"did not\",\n",
    "  \"doesn't\": \"does not\",\n",
    "  \"don't\": \"do not\",\n",
    "  \"hadn't\": \"had not\",\n",
    "  \"hadn't've\": \"had not have\",\n",
    "  \"hasn't\": \"has not\",\n",
    "  \"haven't\": \"have not\",\n",
    "  \"he'd\": \"he would\",\n",
    "  \"he'd've\": \"he would have\",\n",
    "  \"he'll\": \"he will\",\n",
    "  \"he'll've\": \"he will have\",\n",
    "  \"he's\": \"he is\",\n",
    "  \"how'd\": \"how did\",\n",
    "  \"how'd'y\": \"how do you\",\n",
    "  \"how'll\": \"how will\",\n",
    "  \"how's\": \"how is\",\n",
    "  \"i'd\": \"i would\",\n",
    "  \"i'd've\": \"i would have\",\n",
    "  \"i'll\": \"i will\",\n",
    "  \"i'll've\": \"i will have\",\n",
    "  \"i'm\": \"i am\",\n",
    "  \"i've\": \"i have\",\n",
    "  \"isn't\": \"is not\",\n",
    "  \"it'd\": \"it had\",\n",
    "  \"it'd've\": \"it would have\",\n",
    "  \"it'll\": \"it will\",\n",
    "  \"it'll've\": \"it will have\",\n",
    "  \"it's\": \"it is\",\n",
    "  \"let's\": \"let us\",\n",
    "  \"ma'am\": \"madam\",\n",
    "  \"mayn't\": \"may not\",\n",
    "  \"might've\": \"might have\",\n",
    "  \"mightn't\": \"might not\",\n",
    "  \"mightn't've\": \"might not have\",\n",
    "  \"must've\": \"must have\",\n",
    "  \"mustn't\": \"must not\",\n",
    "  \"mustn't've\": \"must not have\",\n",
    "  \"needn't\": \"need not\",\n",
    "  \"needn't've\": \"need not have\",\n",
    "  \"o'clock\": \"of the clock\",\n",
    "  \"oughtn't\": \"ought not\",\n",
    "  \"oughtn't've\": \"ought not have\",\n",
    "  \"shan't\": \"shall not\",\n",
    "  \"sha'n't\": \"shall not\",\n",
    "  \"shan't've\": \"shall not have\",\n",
    "  \"she'd\": \"she would\",\n",
    "  \"she'd've\": \"she would have\",\n",
    "  \"she'll\": \"she will\",\n",
    "  \"she'll've\": \"she will have\",\n",
    "  \"she's\": \"she is\",\n",
    "  \"should've\": \"should have\",\n",
    "  \"shouldn't\": \"should not\",\n",
    "  \"shouldn't've\": \"should not have\",\n",
    "  \"so've\": \"so have\",\n",
    "  \"so's\": \"so is\",\n",
    "  \"that'd\": \"that would\",\n",
    "  \"that'd've\": \"that would have\",\n",
    "  \"that's\": \"that is\",\n",
    "  \"there'd\": \"there had\",\n",
    "  \"there'd've\": \"there would have\",\n",
    "  \"there's\": \"there is\",\n",
    "  \"they'd\": \"they would\",\n",
    "  \"they'd've\": \"they would have\",\n",
    "  \"they'll\": \"they will\",\n",
    "  \"they'll've\": \"they will have\",\n",
    "  \"they're\": \"they are\",\n",
    "  \"they've\": \"they have\",\n",
    "  \"to've\": \"to have\",\n",
    "  \"wasn't\": \"was not\",\n",
    "  \"we'd\": \"we had\",\n",
    "  \"we'd've\": \"we would have\",\n",
    "  \"we'll\": \"we will\",\n",
    "  \"we'll've\": \"we will have\",\n",
    "  \"we're\": \"we are\",\n",
    "  \"we've\": \"we have\",\n",
    "  \"weren't\": \"were not\",\n",
    "  \"what'll\": \"what will\",\n",
    "  \"what'll've\": \"what will have\",\n",
    "  \"what're\": \"what are\",\n",
    "  \"what's\": \"what is\",\n",
    "  \"what've\": \"what have\",\n",
    "  \"when's\": \"when is\",\n",
    "  \"when've\": \"when have\",\n",
    "  \"where'd\": \"where did\",\n",
    "  \"where's\": \"where is\",\n",
    "  \"where've\": \"where have\",\n",
    "  \"who'll\": \"who will\",\n",
    "  \"who'll've\": \"who will have\",\n",
    "  \"who's\": \"who is\",\n",
    "  \"who've\": \"who have\",\n",
    "  \"why's\": \"why is\",\n",
    "  \"why've\": \"why have\",\n",
    "  \"will've\": \"will have\",\n",
    "  \"won't\": \"will not\",\n",
    "  \"won't've\": \"will not have\",\n",
    "  \"would've\": \"would have\",\n",
    "  \"wouldn't\": \"would not\",\n",
    "  \"wouldn't've\": \"would not have\",\n",
    "  \"y'all\": \"you all\",\n",
    "  \"y'alls\": \"you alls\",\n",
    "  \"y'all'd\": \"you all would\",\n",
    "  \"y'all'd've\": \"you all would have\",\n",
    "  \"y'all're\": \"you all are\",\n",
    "  \"y'all've\": \"you all have\",\n",
    "  \"you'd\": \"you had\",\n",
    "  \"you'd've\": \"you would have\",\n",
    "  \"you'll\": \"you you will\",\n",
    "  \"you'll've\": \"you you will have\",\n",
    "  \"you're\": \"you are\",\n",
    "  \"you've\": \"you have\"\n",
    "}\n",
    "\n",
    "Extend contraction dict by other types of quotes which are used in reviews.\n",
    "\n",
    "contractons_dict_ext = {}\n",
    "for k, v in contractons_dict.items():\n",
    "    contractons_dict_ext[k] = v\n",
    "    contractons_dict_ext[k.replace(\"'\", \"`\")] = v\n",
    "    contractons_dict_ext[k.replace(\"'\", \"´\")] = v\n",
    "\n",
    "def rep_contr(match):\n",
    "    'Function expands contractions using dictionary: contractons_dict_ext'\n",
    "    return contractons_dict_ext[match.group(0)]\n",
    "\n",
    "class TextStemmer(TransformerMixin):\n",
    "    def __init__(self, stemmer = 'nltk_porter_stemmer', stop_words_list=nltk.corpus.stopwords.words('english'), punctuation_list=string.punctuation, expand_contractions = True):\n",
    "        self.params_ = {'stemmer': stemmer, 'stop_words_list': stop_words_list, 'punctuation_list': punctuation_list, 'expand_contractions': expand_contractions}\n",
    "        \n",
    "    def fit(self, X, y=None, **kwargs):\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X,  **kwargs):\n",
    "        \n",
    "        # make text lower case\n",
    "        X = [text.lower() for text in X] \n",
    "        \n",
    "        if self.params_['stemmer'] == None and self.params_['stop_words_list'] == None \\\n",
    "            and self.params_['punctuation_list'] == None \\\n",
    "            and (self.params_['expand_contractions'] == None or self.params_['expand_contractions'] == False):\n",
    "            # if there aren't any transformations return X\n",
    "                return X\n",
    "        else:\n",
    "            \n",
    "            # expand contractions\n",
    "            if not (self.params_['expand_contractions'] == None or self.params_['expand_contractions'] == False):\n",
    "                X = [re.sub('|'.join(contractons_dict_ext.keys()), rep_contr, text) for text in X] \n",
    "            \n",
    "            # split text to separate words and remove single quote sing (') if it is first letter in a word. Change words to lower case\n",
    "            X =[[word[1:].lower() if word.startswith(\"'\") else word.lower() for word in nltk.word_tokenize(text)] for text in X]            \n",
    "            \n",
    "          \n",
    "            # remove punctuation\n",
    "            if self.params_['punctuation_list'] != None:\n",
    "                X = [[word for word in text if word not in self.params_['punctuation_list']] for text in X]\n",
    "            \n",
    "            # remove stopwords\n",
    "            if self.params_['stop_words_list'] != None:\n",
    "                X = [[word for word in text if word not in self.params_['stop_words_list']] for text in X]\n",
    "                \n",
    "            # use stemmer\n",
    "            if self.params_['stemmer'] == 'nltk_porter_stemmer':\n",
    "                stemmer = nltk.PorterStemmer()\n",
    "                X = [[stemmer.stem(word) for word in text] for text in X]\n",
    "            \n",
    "            # put separate words together into text\n",
    "            X = [\" \".join(text) for text in X]\n",
    "            \n",
    "            return X\n",
    "\n",
    "Define pipelines for data preprocessing.\n",
    "\n",
    "pipe_dict_preproc_data = {}\n",
    "\n",
    "stemmer_dict = {\n",
    "               'expcontr_rempunc_remsw_stemmer' : TextStemmer(expand_contractions=True, punctuation_list=string.punctuation, stop_words_list=nltk.corpus.stopwords.words('english'), stemmer = 'nltk_porter_stemmer' ),\n",
    "               'expcontr_norempunc_noremsw_nostemmer' : TextStemmer(expand_contractions=True, punctuation_list=None, stop_words_list=None, stemmer=None),\n",
    "               'noexpcontr_norempunc_noremsw_nostemmer' : TextStemmer(expand_contractions=None, punctuation_list=None, stop_words_list=None, stemmer=None)\n",
    "               }\n",
    "\n",
    "vectorizer_dict = {\n",
    "                  'countvect5000' : CountVectorizer(max_features=5000, min_df=0.001, max_df=0.5),\n",
    "                  'countvect1000' : CountVectorizer(max_features=1000, min_df=0.001, max_df=0.5),\n",
    "                  'tfidvect5000' : TfidfVectorizer(max_features=5000, min_df=0.001, max_df=0.5),\n",
    "                  'tfidvect1000' : TfidfVectorizer(max_features=1000, min_df=0.001, max_df=0.5)\n",
    "                  }\n",
    "\n",
    "for stemmer_key, stemmer_obj in stemmer_dict.items():\n",
    "    for vectorizer_key, vectorizer_obj in vectorizer_dict.items():\n",
    "        \n",
    "        pipe_key = stemmer_key + '_' + vectorizer_key\n",
    "        pipe = Pipeline([('stemmer', stemmer_obj), ('vectorizer', vectorizer_obj)])\n",
    "        pipe_dict_preproc_data[pipe_key] = pipe\n",
    "\n",
    "\n",
    "# Example of manual definition for dict: pipe_dict_preproc_data definition (above loop is used for convenience)\n",
    "# pipe_key = 'stemmer_sw_punc_tfidvect5000'\n",
    "# pipe = Pipeline([('stemmer', TextStemmer(stemmer=None)), ('vectorizer', TfidfVectorizer(max_features=5000, min_df=0.001, max_df=0.5))])\n",
    "# pipe_dict_preproc_data[pipe_key] = pipe\n",
    "\n",
    "Preprocess data using pipelines defined above to the form to be used in model estimation.\n",
    "\n",
    "X_train_dict_preprocessed = {k : v.fit_transform(X_train) for (k, v) in pipe_dict_preproc_data.items()}\n",
    "X_test_dict_preprocessed = {k : v.transform(X_test) for (k, v) in pipe_dict_preproc_data.items()}\n",
    "\n",
    "## Classic model estimation setting\n",
    "\n",
    "Define dictionaries to store estimated models.\n",
    "\n",
    "gs_dict_gs = {}\n",
    "gs_dict_best_estimator = {}\n",
    "gs_dict_best_estimator_measures = {}\n",
    "df_dict_gs_detail_res = {}\n",
    "df_classic_models_res = None\n",
    "\n",
    "def run_grid_search(pipe_key, pipe, grid_params):\n",
    "    'Function runs grid search and collects results'\n",
    "    \n",
    "    for data_key, X_train_preproc in X_train_dict_preprocessed.items():\n",
    "\n",
    "        dict_key = data_key + ' & ' + pipe_key\n",
    "        print(\"Estimating: \", data_key, pipe_key)\n",
    "\n",
    "        grid_search = GridSearchCV(pipe, grid_params, n_jobs=-1, scoring={'accuracy_score' : 'accuracy', 'roc_auc_score': 'roc_auc' }, refit='accuracy_score', return_train_score=True)\n",
    "        %timeit -r 1 grid_search.fit(X_train_preproc, y_train)\n",
    "\n",
    "        # save grid search results\n",
    "        gs_dict_gs[dict_key] = grid_search\n",
    "        gs_dict_best_estimator[dict_key] = grid_search.best_estimator_\n",
    "        gs_dict_best_estimator_measures[dict_key] = grid_search.best_score_\n",
    "        \n",
    "        df_dict_gs_detail_res[pipe_key] = detail_est_res_to_df(gs_dict_gs, pipe_key)\n",
    "    \n",
    "    IPython.display.display(df_dict_gs_detail_res[pipe_key])\n",
    "    \n",
    "\n",
    "def detail_est_res_to_df(dict_est_results, pipe_key, gs_dict_gs=gs_dict_gs):\n",
    "    '''\n",
    "    Function converts dictionary with grid search results to pandas data frame in order to \n",
    "    analyze grid search parameters vs model performance\n",
    "    '''\n",
    "    \n",
    "    # filter input dictionary by pipe_key\n",
    "    dict_est_results = {k : v for (k,v) in dict_est_results.items() if k.endswith('& ' + pipe_key) == True}\n",
    "   \n",
    "    df_list = []\n",
    "    # for each gs result create data frame containing gs parameters and measures values\n",
    "    for dict_key, gs_res in dict_est_results.items():\n",
    "        df_list.append(\n",
    "                pd.concat((\n",
    "                    pd.Series([dict_key.split('&')[0].strip() for x in range(len(dict_est_results[dict_key].cv_results_['params']))], name='input_data'),\n",
    "                    pd.Series([dict_key.split('&')[1].strip() for x in range(len(dict_est_results[dict_key].cv_results_['params']))], name='model_name'),\n",
    "                    pd.DataFrame(dict_est_results[dict_key].cv_results_['params']), \n",
    "                    \n",
    "                    pd.Series( [(0 if param != dict_est_results[dict_key].best_params_ else 1) \\\n",
    "                                for param in dict_est_results[dict_key].cv_results_['params']], name = 'best_param_ind' ),\n",
    "                    \n",
    "                    pd.Series(gs_dict_gs[dict_key].cv_results_['mean_train_accuracy_score'], name = 'mean_train_accuracy_score'),\n",
    "                    pd.Series(gs_dict_gs[dict_key].cv_results_['mean_test_accuracy_score'], name = 'mean_test_accuracy_score'),\n",
    "                    pd.Series(gs_dict_gs[dict_key].cv_results_['mean_train_accuracy_score'] - gs_dict_gs[dict_key].cv_results_['mean_test_accuracy_score'], name = 'mean_train_test_accuracy_score_dif'),\n",
    "                    \n",
    "                    pd.Series(gs_dict_gs[dict_key].cv_results_['mean_train_roc_auc_score'], name = 'mean_train_roc_auc_score'),\n",
    "                    pd.Series(gs_dict_gs[dict_key].cv_results_['mean_test_roc_auc_score'], name = 'mean_test_roc_auc_score'),\n",
    "                    pd.Series(gs_dict_gs[dict_key].cv_results_['mean_train_roc_auc_score'] - gs_dict_gs[dict_key].cv_results_['mean_test_roc_auc_score'], name = 'mean_train_test_roc_auc_score_dif')\n",
    "                ),\n",
    "                    axis=1))\n",
    "    \n",
    "    \n",
    "    return pd.concat(df_list)\n",
    "\n",
    "def est_res_to_df(dict_est_results):\n",
    "    'Function converts dictionary with grid search results to pandas data frame'\n",
    "    \n",
    "    col_index = dict_est_results.keys()\n",
    "    col_means_val = [v.best_score_ for v in dict_est_results.values()]\n",
    "    col_best_params = [v.best_params_ for v in dict_est_results.values()]\n",
    "    dict_index_best_param = {k: (v.cv_results_['params'].index(v.best_params_)) for k,v in gs_dict_gs.items()}\n",
    "    \n",
    "    \n",
    "    col_train_acc_score = { k1 : gs_dict_gs[k1].cv_results_['mean_train_accuracy_score'][v1] for (k1 , v1) in dict_index_best_param.items()}\n",
    "    col_test_acc_score = { k1 : gs_dict_gs[k1].cv_results_['mean_test_accuracy_score'][v1] for (k1 , v1) in dict_index_best_param.items()}\n",
    "\n",
    "    col_train_roc_auc_score = { k1 : gs_dict_gs[k1].cv_results_['mean_train_roc_auc_score'][v1] for (k1 , v1) in dict_index_best_param.items()}\n",
    "    col_test_roc_auc_score = { k1 : gs_dict_gs[k1].cv_results_['mean_test_roc_auc_score'][v1] for (k1 , v1) in dict_index_best_param.items()}\n",
    "    \n",
    "    df_est_results = pd.DataFrame(pd.Series(data=col_means_val, index = col_index, name='measure_value'))\n",
    "    df_est_results=df_est_results.assign(input_data = df_est_results.index.str.extract('(.*)&.*', expand=False).get_values())\n",
    "    df_est_results=df_est_results.assign(model_name = df_est_results.index.str.extract('.*&(.*)', expand=False).get_values())\n",
    "    df_est_results=df_est_results.assign(best_params = col_best_params)\n",
    "    df_est_results=df_est_results.assign(mean_train_accuracy_score = col_train_acc_score.values())\n",
    "    df_est_results=df_est_results.assign(mean_test_accuracy_score = col_test_acc_score.values())\n",
    "    df_est_results['mean_train_test_accuracy_score_dif'] = df_est_results['mean_train_accuracy_score'] - df_est_results['mean_test_accuracy_score']\n",
    "\n",
    "    df_est_results=df_est_results.assign(mean_train_roc_auc_score = col_train_roc_auc_score.values())\n",
    "    df_est_results=df_est_results.assign(mean_test_roc_auc_score = col_test_roc_auc_score.values())\n",
    "    df_est_results['mean_train_test_auc_roc_score_dif'] = df_est_results['mean_train_roc_auc_score'] - df_est_results['mean_test_roc_auc_score']\n",
    "\n",
    "    df_est_results.reset_index(inplace=True, drop=True)\n",
    "    \n",
    "    return df_est_results\n",
    "\n",
    "## Logistic Regression\n",
    "\n",
    "pipe_key = \"LOG_REG\"\n",
    "pipe = Pipeline([('model', LogisticRegression())])\n",
    "grid_params = [{'model__C':[0.01, 0.1, 1, 10], 'model__penalty':['l1', 'l2']}]\n",
    "\n",
    "run_grid_search(pipe_key, pipe, grid_params)\n",
    "\n",
    "pipe_key = \"svd_LOG_REG\"\n",
    "pipe = Pipeline([('selection', TruncatedSVD()), ('model', LogisticRegression())])\n",
    "grid_params = [{'selection__n_components':[10, 50, 100], 'model__C':[0.01, 0.1, 1, 10]}]\n",
    "\n",
    "run_grid_search(pipe_key, pipe, grid_params)\n",
    "\n",
    "## SVM\n",
    "\n",
    "# Due to long computation time SVM model was calculated only on variables resulting from SVD decomposition\n",
    "pipe_key = \"svm\"\n",
    "pipe = Pipeline([('selection', TruncatedSVD()), ('model', SVC())])\n",
    "grid_params = [{'selection__n_components':[500], 'model__C':[ 20, 50, 100]}]\n",
    "\n",
    "run_grid_search(pipe_key, pipe, grid_params)\n",
    "\n",
    "## Random Forest\n",
    "\n",
    "pipe_key = \"random_forest\"\n",
    "pipe = Pipeline([('model', RandomForestClassifier())])\n",
    "grid_params = [{'model__min_samples_leaf':[1, 2, 5, 10, 20, 50], 'model__n_estimators':[10, 100, 500, 1000]}]\n",
    "\n",
    "run_grid_search(pipe_key, pipe, grid_params)\n",
    "\n",
    "## Naive Bayes\n",
    "\n",
    "pipe_key = \"naive_bayes\"\n",
    "pipe = Pipeline([('model', MultinomialNB())])\n",
    "grid_params = [{'model__alpha':[0, 1, 10, 50]}]\n",
    "\n",
    "run_grid_search(pipe_key, pipe, grid_params)\n",
    "\n",
    "\n",
    "## XGBoost\n",
    "\n",
    "pipe_key = \"xgboost\"\n",
    "pipe = Pipeline([('model', XGBClassifier())])\n",
    "grid_params = [{'model__n_estimators':[100, 500, 1000], 'model__learning_rate': [0.05, 0.1, 0.3, 1]}]\n",
    "\n",
    "run_grid_search(pipe_key, pipe, grid_params)\n",
    "\n",
    "## Summarize classic models\n",
    "\n",
    "df_classic_models_res = est_res_to_df(gs_dict_gs)\n",
    "df_classic_models_res.to_csv(\"02 Output data/df_classic_models_est_results.csv\")\n",
    "df_classic_models_res\n",
    "\n",
    "Show 10 best results.\n",
    "\n",
    "df_classic_models_res.sort_values('mean_test_accuracy_score', ascending=False).head(10)\n",
    "\n",
    "def create_df_dict_gs_detail_res2():\n",
    "    'Function creates df with detail estimation results unified for all classical model types'\n",
    "    \n",
    "    df_dict_gs_detail_res2 = {}\n",
    "    for model_id, df_res in df_dict_gs_detail_res.items():\n",
    "        df = df_dict_gs_detail_res[model_id].reset_index()\n",
    "        df_dict_gs_detail_res2[model_id]=df.melt(id_vars=['index', 'input_data', 'model_name', 'best_param_ind', 'mean_train_accuracy_score',\\\n",
    "               'mean_test_accuracy_score', 'mean_train_test_accuracy_score_dif',\\\n",
    "               'mean_train_roc_auc_score', 'mean_test_roc_auc_score',\\\n",
    "               'mean_train_test_roc_auc_score_dif'],\n",
    "               var_name='Parameter_name', value_name='Parameter_value')\n",
    "    df_detail_res = pd.concat(df_dict_gs_detail_res2.values(),axis=0)\n",
    "    return df_detail_res\n",
    "\n",
    "Save concatenated detail estimation results.\n",
    "\n",
    "df_detail_res_to_csv = create_df_dict_gs_detail_res2()\n",
    "df_detail_res_to_csv.to_csv(\"02 Output data/df_classic_models_est_results_details.csv\", sep=\";\", decimal=',')\n",
    "\n",
    "Save estimation results to files (without unification done above).\n",
    "\n",
    "for model_id, df_res in df_dict_gs_detail_res.items():\n",
    "    df_dict_gs_detail_res[model_id].to_csv(\"02 Output data/df_classic_models_est_results_details_\" + model_id + \".csv\", sep=\";\", decimal=',')\n",
    "\n",
    "Model performance comparison.\n",
    "\n",
    "df_detail_res_to_plot = df_detail_res_to_csv[df_detail_res_to_csv.best_param_ind==1].sort_values(['mean_test_accuracy_score'], ascending = False)\n",
    "df_detail_res_to_plot.boxplot(column='mean_test_accuracy_score', by='model_name', figsize=(10,10), vert=False)\n",
    "plt.show()\n",
    "\n",
    "### Conclusions for the plot above\n",
    "\n",
    "The best model is Logistic Regression which is slightly surprising. XGBoost and SVM are slightly worse.\n",
    "It is possible that better tuning of hyperparameters for XGBoost and SVM could result in better performance (at least on LR level)\n",
    "Using SVD to preselect variables for Logistic Regression gives unsatisfactory results.\n",
    "Logistic regression gives the best accuracy score (0.87850).\n",
    "\n",
    "df_detail_res_to_plot2 = df_detail_res_to_plot\n",
    "df_detail_res_to_plot2['num_words'] = df_detail_res_to_plot2.input_data.str[-4:]\n",
    "df_detail_res_to_plot2.boxplot(column='mean_test_accuracy_score', by=['num_words', 'input_data'], figsize=(10,10), rot=0, vert=False)\n",
    "plt.show()\n",
    "\n",
    "### Conclusions\n",
    "\n",
    "Data above are group by number of words (5000 - first part, 1000 word - second part)\n",
    "Using 1000 words as a base for estimation gives noticeable worse result than estimation on 5000 words.\n",
    "Preprocessing data (expanding contraction, removing punctuation and stop words and using stemmer) gives slightly worse performance than data which are not preprocessed in any way. In chart below TFIdf and Count Vectorizers interweave. It is noticeable that using count vectorizer give slightly worse performance than using TFidf Vectorizer.\n",
    "\n",
    "## Recurrent Neural Networks\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import SimpleRNN, Dense, Embedding, LSTM, GRU, GlobalAveragePooling1D, Bidirectional\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras import regularizers\n",
    "\n",
    "num_cores = 4\n",
    "\n",
    "# use CPU or GPU\n",
    "num_CPU = 1\n",
    "num_GPU = 0 #set 1 if you want to run calculations on GPU\n",
    "\n",
    "config = tf.ConfigProto(intra_op_parallelism_threads=num_cores,\\\n",
    "        inter_op_parallelism_threads=num_cores, allow_soft_placement=True,\\\n",
    "        device_count = {'CPU' : num_CPU, 'GPU' : num_GPU})\n",
    "session = tf.Session(config=config)\n",
    "K.set_session(session)\n",
    "\n",
    "class Rnn_Tokenizer(TransformerMixin):\n",
    "    'Assigns integers to words and creates integer sequences (by transform method)'\n",
    "    \n",
    "    def __init__(self, num_words = None, max_seq_length = None):\n",
    "        self.num_words_ = num_words\n",
    "        self.max_seq_length_ = max_seq_length\n",
    "        \n",
    "    def fit(self, X, max_seq_length = None):\n",
    "        \n",
    "        self.tokenizer = Tokenizer(num_words = self.num_words_)\n",
    "        self.tokenizer.fit_on_texts(X)\n",
    "        \n",
    "        if self.max_seq_length_ == None:\n",
    "            self.max_seq_length_ = max([len(l) for l in self.tokenizer.texts_to_sequences(X)])\n",
    "        \n",
    "        return self\n",
    "        \n",
    "    def transform(self, X, **kwargs):            \n",
    "        int_text = self.tokenizer.texts_to_sequences(X)\n",
    "        return pad_sequences(int_text, maxlen=self.max_seq_length_)\n",
    "        \n",
    "        \n",
    "\n",
    "par_max_num_words = 200000 #parameter value indicates max number of words which is possible to be used in model estimation\n",
    "\n",
    "Calculate maximum number of words in review (after removing punctuation) for concatenated train and test sets.\n",
    "\n",
    "rnn_pipe = Pipeline([('nostemmer_nosw_punc', TextStemmer(stemmer=None, stop_words_list=None, punctuation_list=string.punctuation))\n",
    "                     , ('rnn_tokenizer', Rnn_Tokenizer(num_words=par_max_num_words))\n",
    "                     ])\n",
    "rnn_pipe.fit_transform(np.concatenate((kaggle_input_data_train['review'].values, kaggle_input_data_test['review'].values)))\n",
    "par_max_seq_length_calculated = rnn_pipe.steps[1][1].max_seq_length_\n",
    "par_max_seq_length_calculated\n",
    "\n",
    "par_max_seq_length=400 #set manually maximum sequence length (=maximum number of words in review) to reduce computation time\n",
    "\n",
    "### Read embeddings\n",
    "\n",
    "Read embeddings and filter them by words which occur in reviews (train and test sets). This step creates two numpy arrays: emb_words (array of words), emb_vectors (array of embeddings values)\n",
    "\n",
    "par_embedding_length = 300\n",
    "\n",
    "with open('01 Input data/glove.6B.' + str(par_embedding_length) + 'd.txt', encoding=\"utf8\") as f:\n",
    "    i = 1\n",
    "    emb_words = np.empty((par_max_num_words+1), dtype='object')\n",
    "    emb_vectors = np.zeros((par_max_num_words+1, par_embedding_length))\n",
    "    emb_words[0] = ''\n",
    "    for line in f:\n",
    "\n",
    "        line_list = line.split(' ')\n",
    "        \n",
    "        \n",
    "        try:\n",
    "            rnn_pipe.steps[1][1].tokenizer.word_index[line_list[0]]    \n",
    "        except KeyError:\n",
    "            pass\n",
    "        else:\n",
    "            if i <= par_max_num_words:\n",
    "                emb_words[i] = line_list[0]\n",
    "                emb_vectors[i] = line_list[1:]\n",
    "            i = i + 1\n",
    "\n",
    "Sample of first 1000 words in embeddings.\n",
    "\n",
    "for i in range(min(1000, par_max_num_words)):\n",
    "    print(emb_words[i])\n",
    "\n",
    "Check which words are in reviews and aren't in embeddings.\n",
    "\n",
    "words_in_reviews_not_in_emb = []\n",
    "for word in rnn_pipe.steps[1][1].tokenizer.word_index.keys():\n",
    "    if word not in emb_words:\n",
    "        words_in_reviews_not_in_emb.append(word)\n",
    "\n",
    "words_in_reviews_not_in_emb\n",
    "\n",
    "Preliminary analysis indicated that:\n",
    "1. words such as: \"'real\", \"'love\" that is  with single quote sign (') at the beginning appear in list\n",
    "2. words such as: \"it´s\", \"didn't\", \"don't\", \"i'm\" that are shortcuts appear quite often\n",
    "\n",
    "\n",
    "To address these issues TextStemmer class was extended so that:\n",
    "Ad 1. Single quote sign (') appearing at the beginning of the word is removed\n",
    "Ad 2. Common contractions are expanded to full words.\n",
    "Preliminary list contained in total: 32832 words. List after applying steps 1. and 2. contains: 27947 words.\n",
    "Usually words on the list below are spelling errors or uncommon words.\n",
    "\n",
    "# Number of word in reviews but not in embeddings vector\n",
    "len(words_in_reviews_not_in_emb)\n",
    "\n",
    "### Data preprocessing for RNN\n",
    "\n",
    "Create Pipelines for data preprocessing.\n",
    "\n",
    "dict_rnn_pipe = {}\n",
    "\n",
    "text_stemmer_key = 'nostemmer_nosw_punc_expcontr'\n",
    "text_stemmer_obj = TextStemmer(stemmer=None, stop_words_list=None, punctuation_list=string.punctuation, expand_contractions = True)\n",
    "\n",
    "\n",
    "rnn_tokenizer_key = 'rnn_tokenizer_1000'\n",
    "rnn_tokenizer_obj = Rnn_Tokenizer(num_words=1000, max_seq_length=par_max_seq_length)\n",
    "rnn_pipe = Pipeline([(text_stemmer_key, text_stemmer_obj), (rnn_tokenizer_key, rnn_tokenizer_obj)])\n",
    "dict_rnn_pipe[text_stemmer_key + '__' + rnn_tokenizer_key] = rnn_pipe\n",
    "\n",
    "\n",
    "rnn_tokenizer_key = 'rnn_tokenizer_5000'\n",
    "rnn_tokenizer_obj = Rnn_Tokenizer(num_words=5000, max_seq_length=par_max_seq_length)\n",
    "rnn_pipe = Pipeline([(text_stemmer_key, text_stemmer_obj), (rnn_tokenizer_key, rnn_tokenizer_obj)])\n",
    "dict_rnn_pipe[text_stemmer_key + '__' + rnn_tokenizer_key] = rnn_pipe\n",
    "\n",
    "\n",
    "rnn_tokenizer_key = 'rnn_tokenizer_20000'\n",
    "rnn_tokenizer_obj = Rnn_Tokenizer(num_words=20000, max_seq_length=par_max_seq_length)\n",
    "rnn_pipe = Pipeline([(text_stemmer_key, text_stemmer_obj), (rnn_tokenizer_key, rnn_tokenizer_obj)])\n",
    "dict_rnn_pipe[text_stemmer_key + '__' + rnn_tokenizer_key] = rnn_pipe\n",
    "\n",
    "Run Pipelines for data preprocessing.\n",
    "\n",
    "rnn_X_train_dict_preprocessed = {}\n",
    "rnn_X_test_dict_preprocessed = {}\n",
    "\n",
    "for pipe_key, pipe in dict_rnn_pipe.items():\n",
    "    rnn_X_train_dict_preprocessed[pipe_key] = pipe.fit_transform(X_train)\n",
    "    rnn_X_test_dict_preprocessed[pipe_key] = pipe.transform(X_test)\n",
    "\n",
    "def create_embeddding_weights(tokenizer, emb_words, emb_vectors):\n",
    "    '''\n",
    "    Function creates embedding matrix to be used in Embedding layer and creates dictionary with\n",
    "    words which do not have representation in embedding vector\n",
    "    '''\n",
    "\n",
    "    embeddings = np.zeros((tokenizer.num_words + 1, par_embedding_length))\n",
    "    words_not_in_embeddings = {}\n",
    "    \n",
    "    for word, word_int in tokenizer.word_index.items():\n",
    "        if word_int <= tokenizer.num_words:\n",
    "            if np.nonzero(emb_words==word)[0].shape[0] == 0:\n",
    "                words_not_in_embeddings[word] = word_int\n",
    "            else:\n",
    "                embeddings[word_int, :] = emb_vectors[np.nonzero(emb_words==word)[0]]\n",
    "    return embeddings, words_not_in_embeddings\n",
    "\n",
    "Create embedding matrices to be used in Embedding layer and create dictionaries with words which do not have representation in embedding vector.\n",
    "\n",
    "rnn_X_train_embeddings = {}\n",
    "rnn_X_test_embeddings = {}\n",
    "rnn_X_train_words_not_in_embeddings = {}\n",
    "\n",
    "\n",
    "for pipe_key, pipe in dict_rnn_pipe.items():\n",
    "    \n",
    "    tokenizer = dict_rnn_pipe[pipe_key].steps[1][1].tokenizer\n",
    "    rv = create_embeddding_weights(tokenizer, emb_words, emb_vectors)\n",
    "    \n",
    "    rnn_X_train_embeddings[pipe_key] = rv[0]\n",
    "    rnn_X_test_embeddings[pipe_key] = rv[0]\n",
    "    rnn_X_train_words_not_in_embeddings[pipe_key] = rv[1]\n",
    "\n",
    "del rv\n",
    "\n",
    "### Estimation of RNN models\n",
    "\n",
    "def create_rnn_models(dict_rnn_pipe, rnn_embeddings):\n",
    "    'Function defines RNN models'\n",
    "    \n",
    "    rnn_models_dict = {}\n",
    "    \n",
    "    for pipe_key, pipe in dict_rnn_pipe.items(): \n",
    "    \n",
    "        model_key = \"Simple RNN\"\n",
    "        \n",
    "        model = Sequential()\n",
    "        model.add(Embedding(dict_rnn_pipe[pipe_key].steps[1][1].tokenizer.num_words+1, par_embedding_length, input_length=par_max_seq_length, trainable=False, weights=[rnn_embeddings[pipe_key]]))\n",
    "        model.add(SimpleRNN(100))\n",
    "        model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "        model.compile(loss=\"binary_crossentropy\",optimizer=\"adam\",metrics=[\"accuracy\"])\n",
    "        rnn_models_dict[pipe_key + '__' + model_key] = model\n",
    "        \n",
    "        \n",
    "        model_key = \"LSTM\"\n",
    "        \n",
    "        model = Sequential()\n",
    "        model.add(Embedding(dict_rnn_pipe[pipe_key].steps[1][1].tokenizer.num_words+1, par_embedding_length, input_length=par_max_seq_length, trainable=False, weights=[rnn_embeddings[pipe_key]]))\n",
    "        model.add(LSTM(100))\n",
    "        model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "        model.compile(loss=\"binary_crossentropy\",optimizer=\"adam\",metrics=[\"accuracy\"])\n",
    "        rnn_models_dict[pipe_key + '__' + model_key] = model\n",
    "        \n",
    "        model_key = \"LSTM Bidirectional\"\n",
    "        \n",
    "        model = Sequential()\n",
    "        model.add(Embedding(dict_rnn_pipe[pipe_key].steps[1][1].tokenizer.num_words+1, par_embedding_length, input_length=par_max_seq_length, trainable=False, weights=[rnn_embeddings[pipe_key]]))\n",
    "        model.add(Bidirectional(LSTM(100)))\n",
    "        model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "        model.compile(loss=\"binary_crossentropy\",optimizer=\"adam\",metrics=[\"accuracy\"])\n",
    "        rnn_models_dict[pipe_key + '__' + model_key] = model\n",
    "\n",
    "                \n",
    "        model_key = \"LSTM Bidirectional with dropout\"\n",
    "        \n",
    "        model = Sequential()\n",
    "        model.add(Embedding(dict_rnn_pipe[pipe_key].steps[1][1].tokenizer.num_words+1, par_embedding_length, input_length=par_max_seq_length, trainable=False, weights=[rnn_embeddings[pipe_key]]))\n",
    "        model.add(Bidirectional(LSTM(100,dropout=0.3,recurrent_dropout=0.3)))\n",
    "        model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "        model.compile(loss=\"binary_crossentropy\",optimizer=\"adam\",metrics=[\"accuracy\"])\n",
    "        rnn_models_dict[pipe_key + '__' + model_key] = model\n",
    "\n",
    "        \n",
    "        \n",
    "        model_key = \"GRU\"\n",
    "        \n",
    "        model = Sequential()\n",
    "        model.add(Embedding(dict_rnn_pipe[pipe_key].steps[1][1].tokenizer.num_words+1, par_embedding_length, input_length=par_max_seq_length, trainable=False, weights=[rnn_embeddings[pipe_key]]))\n",
    "        model.add(GRU(100))\n",
    "        model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "        model.compile(loss=\"binary_crossentropy\",optimizer=\"adam\",metrics=[\"accuracy\"])\n",
    "        rnn_models_dict[pipe_key + '__' + model_key] = model\n",
    "\n",
    "        model_key = \"GRU Bidirectional\"\n",
    "        \n",
    "        model = Sequential()\n",
    "        model.add(Embedding(dict_rnn_pipe[pipe_key].steps[1][1].tokenizer.num_words+1, par_embedding_length, input_length=par_max_seq_length, trainable=False, weights=[rnn_embeddings[pipe_key]]))\n",
    "        model.add(Bidirectional(GRU(100)))\n",
    "        model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "        model.compile(loss=\"binary_crossentropy\",optimizer=\"adam\",metrics=[\"accuracy\"])\n",
    "        rnn_models_dict[pipe_key + '__' + model_key] = model\n",
    "        \n",
    "                  \n",
    "        model_key = \"GRU Bidirectional with dropout\"\n",
    "        \n",
    "        model = Sequential()\n",
    "        model.add(Embedding(dict_rnn_pipe[pipe_key].steps[1][1].tokenizer.num_words+1, par_embedding_length, input_length=par_max_seq_length, trainable=False, weights=[rnn_embeddings[pipe_key]]))\n",
    "        model.add(Bidirectional(GRU(100,dropout=0.3,recurrent_dropout=0.3)))\n",
    "        model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "        model.compile(loss=\"binary_crossentropy\",optimizer=\"adam\",metrics=[\"accuracy\"])\n",
    "        rnn_models_dict[pipe_key + '__' + model_key] = model\n",
    "\n",
    "\n",
    "    return rnn_models_dict\n",
    "\n",
    "Create dict with RNN models.\n",
    "\n",
    "rnn_models_dict = create_rnn_models(dict_rnn_pipe, rnn_X_train_embeddings)\n",
    "\n",
    "Fit models and evaluate performance.\n",
    "\n",
    "par_batch_size = [32, 128]\n",
    "epochs = 100\n",
    "\n",
    "input_data = []\n",
    "model_name = []\n",
    "acc_train = []\n",
    "acc_test = []\n",
    "batch_size_list = []\n",
    "\n",
    "for model_key, model in rnn_models_dict.items():\n",
    "    \n",
    "    for bs in par_batch_size:\n",
    "        \n",
    "        print(\"\\n******************************************\")\n",
    "        print(\"Model:\", model_key)\n",
    "        print(\"Batch size:\", bs)\n",
    "    \n",
    "        data_key = re.search(r'^(.+__.+)__(.+)$', model_key).group(1)\n",
    "        model_key2 = re.search(r'^(.+__.+)__(.+)$', model_key).group(2)\n",
    "        input_data.append(data_key)\n",
    "        model_name.append(model_key2)\n",
    "\n",
    "        early_stopping = EarlyStopping(patience=3,monitor=\"val_loss\")\n",
    "        take_best = ModelCheckpoint(\"weights.h5py\",save_best_only=True)\n",
    "        rnn_models_dict[model_key].fit(rnn_X_train_dict_preprocessed[data_key], y_train, callbacks=[early_stopping, take_best], validation_split=0.25, batch_size=bs, epochs=epochs)\n",
    "        rnn_models_dict[model_key].load_weights(\"weights.h5py\")\n",
    "        os.remove(\"weights.h5py\")\n",
    "        acc_train.append(rnn_models_dict[model_key].evaluate(rnn_X_train_dict_preprocessed[data_key], y_train)[1])\n",
    "        acc_test.append(rnn_models_dict[model_key].evaluate(rnn_X_test_dict_preprocessed[data_key], y_test)[1])\n",
    "        batch_size_list.append(bs)\n",
    "        \n",
    "        print(\"Results\")\n",
    "        print(\"Model:\", model_key)\n",
    "        print(\"Batch size:\", bs)\n",
    "        print(\"Train:\", acc_train[-1])\n",
    "        print(\"Test:\", acc_test[-1])\n",
    "    \n",
    "df_rnn_model_results = pd.DataFrame({'input_data': input_data, 'model_name': model_name, 'batch_size':batch_size_list, 'train_accuracy_score':acc_train, 'test_accuracy_score':acc_test})\n",
    "\n",
    "### RNN models' results\n",
    "\n",
    "df_rnn_model_results\n",
    "\n",
    "Save estimation results.\n",
    "\n",
    "df_rnn_model_results.to_csv(\"02 Output data\\df_rnn_model_est_results.csv\")\n",
    "\n",
    "Create df for boxplots and show 10 best results.\n",
    "\n",
    "df_rnn_model_results2 = df_rnn_model_results.copy()\n",
    "df_rnn_model_results2['num_words'] = df_rnn_model_results2['input_data'].str.extract('(\\d+)$').astype(float)\n",
    "df_rnn_model_results2.sort_values('test_accuracy_score', ascending=False).head(10)\n",
    "\n",
    "Compare impact of batch size vs estimation results.\n",
    "\n",
    "df_rnn_model_results2.boxplot(column = 'test_accuracy_score', by = ['model_name', 'batch_size'], vert = False, figsize=(10,10))\n",
    "plt.show()\n",
    "\n",
    "Compare model performance vs. number of words.\n",
    "\n",
    "df_rnn_model_results2.boxplot(column = 'test_accuracy_score', by = ['model_name', 'batch_size', 'num_words'], vert = False, figsize=(10,10))\n",
    "plt.show()\n",
    "\n",
    "Compare model performance vs. batch size.\n",
    "\n",
    "df_rnn_model_results2.boxplot(column = 'test_accuracy_score', by = ['model_name', 'num_words', 'batch_size',], vert = False, figsize=(10,10))\n",
    "plt.show()\n",
    "\n",
    "**Conclusions for RNN models' results:**\n",
    "\n",
    "1. Usually batch size 128 gives better results than batch size 32, but batch size 128 takes much more time to estimate\n",
    "2. Usually estimation on 20000 words gives within model type the best results (comparin to 1000 and 5000 words)\n",
    "3. The best accuracy on test sample is reached by GRU Bidirectional with dropout model estimated on 128 batch size and 20000 words\n",
    "\n",
    "## Compare classical models with RNN models\n",
    "\n",
    "# Mark best estimation result for each model as model_rank = 1\n",
    "df_rnn_model_results2['model_rank'] = df_rnn_model_results2.groupby(['model_name'])['test_accuracy_score'].rank(ascending=False)\n",
    "\n",
    "df_classic_models_res2 = df_classic_models_res.copy()\n",
    "df_classic_models_res2['model_rank'] = df_classic_models_res2.groupby(['model_name'])['mean_test_accuracy_score'].rank(ascending=False)\n",
    "df_classic_models_res2.rename(columns={'mean_test_accuracy_score':'test_accuracy_score'}, inplace=True)\n",
    "\n",
    "# Print best results for each model\n",
    "df_model_comparison = pd.concat([df_rnn_model_results2[['model_rank', 'model_name', 'test_accuracy_score']], df_classic_models_res2[['model_rank', 'model_name', 'test_accuracy_score']]], axis=0)\n",
    "df_model_comparison[df_model_comparison['model_rank']==1.].sort_values(['test_accuracy_score'], ascending=False)\n",
    "\n",
    "**Conclusion** <br>\n",
    "Deep learning models on IMDB dataset perform better than classical models (except for Simple RNN)\n",
    "\n",
    "## Data preparation for Kaggle\n",
    "\n",
    "After finding which data preprocessing step and which models work the best for IMDB data set\n",
    "repeat below all the steps above to score test data for Kaggle independent verification.\n",
    "\n",
    "Prepare combined set (X_all = X_train + X_test).\n",
    "\n",
    "X_all = kaggle_input_data_train.review\n",
    "y_all = kaggle_input_data_train.sentiment\n",
    "\n",
    "Dictionaries to store results.\n",
    "\n",
    "kaggle_pipes = {}\n",
    "kaggle_accuracy_score = {} #collects accuracy score on train data set\n",
    "kaggle_roc_auc_score = {} #collects accuracy score on train data set\n",
    "kaggle_predictions_on_kaggle_test_data = {} #dictionary of predictions to be send to Kaggle\n",
    "\n",
    "Estimate best logistic regression model.\n",
    "\n",
    "pipe_key = 'log_reg'\n",
    "\n",
    "pipe = Pipeline([('noexpcontr_norempunc_noremsw_nostemmer', TextStemmer(expand_contractions=None, punctuation_list=None, stop_words_list=None, stemmer=None)),\n",
    "                ('tfidvect5000', TfidfVectorizer(max_features=5000, min_df=0.001, max_df=0.5)),\n",
    "                ('log_reg', LogisticRegression(C=1, penalty = 'l2'))\n",
    "                ])\n",
    "kaggle_pipes[pipe_key + \"_trained_on_X_train\"] = pipe.fit(X_train, y=y_train)\n",
    "kaggle_accuracy_score[pipe_key + \"_trained_on_X_train\"] = accuracy_score(y_train, pipe.predict(X_train))\n",
    "kaggle_roc_auc_score[pipe_key + \"_trained_on_X_train\"] = roc_auc_score(y_train, pipe.predict_proba(X_train)[:,1])\n",
    "\n",
    "kaggle_predictions_on_kaggle_test_data[pipe_key + \"_trained_on_X_train\"] = pd.DataFrame(pipe.predict(kaggle_input_data_test.review), index=kaggle_input_data_test.index)\n",
    "\n",
    "\n",
    "pipe = Pipeline([('noexpcontr_norempunc_noremsw_nostemmer', TextStemmer(expand_contractions=None, punctuation_list=None, stop_words_list=None, stemmer=None)),\n",
    "                ('tfidvect5000', TfidfVectorizer(max_features=5000, min_df=0.001, max_df=0.5)),\n",
    "                ('log_reg', LogisticRegression(C=1, penalty = 'l2'))\n",
    "                ])\n",
    "kaggle_pipes[pipe_key + \"_trained_on_X_all\"] = pipe.fit(X_all, y=y_all)\n",
    "kaggle_accuracy_score[pipe_key + \"_trained_on_X_all\"] = accuracy_score(y_all, pipe.predict(X_all))\n",
    "kaggle_roc_auc_score[pipe_key + \"_trained_on_X_all\"] = roc_auc_score(y_all, pipe.predict_proba(X_all)[:,1])\n",
    "kaggle_predictions_on_kaggle_test_data[pipe_key + \"_trained_on_X_all\"] = pd.DataFrame(pipe.predict(kaggle_input_data_test.review), index=kaggle_input_data_test.index)\n",
    "\n",
    "Show logistic regression accuracy score on train data sets.\n",
    "\n",
    "print(\"Accuracy score:\\n\", kaggle_accuracy_score)\n",
    "print(\"AUC ROC score:\\n\", kaggle_roc_auc_score)\n",
    "\n",
    "Create embeddings matrices.\n",
    "\n",
    "kaggle_rnn_embeddings = {}\n",
    "kaggle_rnn_transformed_data = {}\n",
    "\n",
    "pipe_data = Pipeline([('nostemmer_nosw_punc_expcontr', TextStemmer(stemmer=None, stop_words_list=None, punctuation_list=string.punctuation, expand_contractions = True)),\n",
    "                ('rnn_tokenizer_20000', Rnn_Tokenizer(num_words=20000, max_seq_length=par_max_seq_length))])\n",
    "\n",
    "kaggle_rnn_transformed_data['X_train'] = pipe_data.fit_transform(X_train, y_train)\n",
    "kaggle_rnn_transformed_data['X_kaggle_trained_on_X_train'] = pipe_data.transform(kaggle_input_data_test.review)\n",
    "kaggle_rnn_embeddings['X_train'] = create_embeddding_weights(pipe_data.steps[1][1].tokenizer, emb_words, emb_vectors)[0]\n",
    "\n",
    "\n",
    "pipe_data = Pipeline([('nostemmer_nosw_punc_expcontr', TextStemmer(stemmer=None, stop_words_list=None, punctuation_list=string.punctuation, expand_contractions = True)),\n",
    "                ('rnn_tokenizer_20000', Rnn_Tokenizer(num_words=20000, max_seq_length=par_max_seq_length))])\n",
    "\n",
    "kaggle_rnn_transformed_data['X_all'] = pipe_data.fit_transform(X_all, y_all)\n",
    "kaggle_rnn_transformed_data['X_kaggle_trained_on_X_all'] = pipe_data.transform(kaggle_input_data_test.review)\n",
    "kaggle_rnn_embeddings['X_all'] = create_embeddding_weights(pipe_data.steps[1][1].tokenizer, emb_words, emb_vectors)[0]\n",
    "\n",
    "\n",
    "\n",
    "Estimate best GRU model.\n",
    "\n",
    "pipe_key = 'GRU'\n",
    "bs = 128 #batch size\n",
    "epochs = 100 #maximum number of epochs\n",
    "y_data = {}\n",
    "y_data[\"X_train\"] = y_train\n",
    "y_data[\"X_all\"] = y_all\n",
    "\n",
    "for data_key in ['X_train', 'X_all']:\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(pipe_data.steps[1][1].tokenizer.num_words+1, par_embedding_length, input_length=par_max_seq_length, trainable=False, weights=[kaggle_rnn_embeddings[data_key]]))\n",
    "    model.add(Bidirectional(GRU(100,dropout=0.3,recurrent_dropout=0.3)))\n",
    "    model.add(Dense(1, activation=\"sigmoid\"))\n",
    "    model.compile(loss=\"binary_crossentropy\",optimizer=\"adam\",metrics=[\"accuracy\"])\n",
    "\n",
    "    early_stopping = EarlyStopping(patience=3, monitor=\"val_loss\")\n",
    "    take_best = ModelCheckpoint(\"weights.h5py\", save_best_only=True)\n",
    "    model.fit(kaggle_rnn_transformed_data[data_key], y_data[data_key], callbacks=[early_stopping, take_best], validation_split=0.25, batch_size=bs, epochs=epochs)\n",
    "\n",
    "    model.load_weights(\"weights.h5py\")\n",
    "    os.remove(\"weights.h5py\")\n",
    "    kaggle_accuracy_score[pipe_key + \"_trained_on_\" + data_key] = model.evaluate(kaggle_rnn_transformed_data[data_key], y_data[data_key])[1]\n",
    "    kaggle_roc_auc_score[pipe_key + \"_trained_on_\" + data_key] = roc_auc_score(y_data[data_key], model.predict_proba(kaggle_rnn_transformed_data[data_key]))\n",
    "    kaggle_predictions_on_kaggle_test_data[pipe_key + \"_trained_on_\" + data_key] = pd.DataFrame(model.predict(kaggle_rnn_transformed_data['X_kaggle_trained_on_' + data_key]), index=kaggle_input_data_test.index[:len(kaggle_rnn_transformed_data['X_kaggle_trained_on_' + data_key])])\n",
    "\n",
    "Output data for Kaggle competition.\n",
    "\n",
    "for dict_key, kagle_pred in kaggle_predictions_on_kaggle_test_data.items():\n",
    "    kaggle_predictions_on_kaggle_test_data[dict_key].columns = ['sentiment']\n",
    "    kaggle_predictions_on_kaggle_test_data[dict_key].to_csv('02 Output data/kaggle_pred_' + dict_key + '.csv')\n",
    "\n",
    "Csv files created above are sent to Kaggle for independent verification.\n",
    "\n",
    "# Show models' metrics on train sets\n",
    "kaggle_results = pd.concat([pd.Series(kaggle_accuracy_score, name = 'train_accuracy_score'), pd.Series(kaggle_roc_auc_score, name='train_roc_auc_score')], axis = 1)\n",
    "\n",
    "# Value of roc_auc_score calculated by Kaggle are written below by hand in a code\n",
    "kaggle_results = kaggle_results.assign(kaggle_roc_auc_score = pd.Series({\n",
    "    \"log_reg_trained_on_X_train\":0.88140,\n",
    "    \"log_reg_trained_on_X_all\": 0.88176,\n",
    "    \"GRU_trained_on_X_train\":0.96035,\n",
    "    \"GRU_trained_on_X_all\":0.96446}))\n",
    "\n",
    "kaggle_results\n",
    "\n",
    "ROC_AUC value equal to 0.96446 gives 39 position in Kaggle tutorial competition leader board (among 528 teams) <br>\n",
    "Link for the tutorial competition: <br>\n",
    "https://www.kaggle.com/c/word2vec-nlp-tutorial\n",
    "\n",
    "## Final conclusions\n",
    "\n",
    "#### Classical models:\n",
    "\n",
    "1. The best model among classical models is Logistic Regression which is slightly surprising. \n",
    "2. XGBoost and SVM are slightly worse (SVM is calculated on 500 variables resulting from SVD decomposition).\n",
    "3. It is possible that better tuning of hyperparameters for XGBoost and SVM could result in better performance (at least reaching logistic regression level).\n",
    "4. Using SVD to preselect variables for Logistic Regression gives unsatisfactory results.\n",
    "5. Logistic regression gives the best test accuracy score (0.87850)\n",
    "6. Using 1000 words as a base for estimation gives noticeable worse result than estimation on 5000 most popular words.\n",
    "7. Preprocessing data (expanding contraction, removing punctuation and stop words and using stemmer) gives slightly worse performance than data which are not preprocessed in any way.\n",
    "8. Using count vectorizer gives slightly worse performance than using TFidf Vectorizer.\n",
    "\n",
    "\n",
    "#### RNN models:\n",
    "\n",
    "1. Usually batch size 128 gives better results than batch size 32, but batch size 128 takes much more time to estimate.\n",
    "2. Usually estimation on 20000 words gives within model type the best results (comparing to 1000 and 5000 words).\n",
    "3. The best accuracy (0.90000) on test sample is reached by GRU Bidirectional with dropout model estimated on 128 batch size and 20000 words.\n",
    "\n",
    "#### Classical models vs RNN models:\n",
    "\n",
    "1. Deep learning models on IMDB dataset perform better than classical models (except for Simple RNN).\n",
    "\n",
    "#### Kaggle tutorial competition:\n",
    "\n",
    "1. ROC_AUC value equal to 0.96446 (from GRU Bidirectional with dropout model) gives 39 position in Kaggle tutorial competition leader board (among 528 teams).\n",
    "2. ROC_AUC for Logistic regression model is 0.88176 which is significantly worse than result from GRU Bidirectional with dropout model (0.96446)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
